# <center> NYC TLC Trip Record Data Project </center>
---

Data Source: [Website](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/projects/datasets.md)

---

### Overview:
- [x] Selecting a dataset of interest (see [Datasets](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/projects#datasets))
- [ ] Creating a pipeline for processing this dataset and putting it to a data lake
- [ ] Creating a pipeline for moving the data from the lake to a data warehouse
- [ ] Transforming the data in the data warehouse: prepare it for the dashboard
- [ ] Building a dashboard to visualize the data

--

### Data Pipelines:
- [ ] __Stream:__ If you want to consume data in real-time and put them to data lake
- [x] __Batch:__ If you want to run things periodically (e.g. hourly/daily)

---

### Technology Stack:
__Cloud Platform:__
- [x] AWS
- [ ] GCP
- [ ] Azure
- [ ] ...

__Containerization:__
- [x] Docker
- [ ] ...

__Infrastructure-as-Code (IaC):__
- [x] Terraform
- [ ] Pulumi
- [ ] CloudFormation
- [ ] ...

__Workflow Orchestration:__
- [x] Mage
- [ ] Airflow
- [ ] Prefect
- [ ] Luigi
- [ ] ...

__Data Warehouse:__
- [ ] BigQuery
- [ ] Snowflake
- [x] Redshift
- [ ] ...

__Batch Processing:__
- [ ] Spark
- [ ] Flink
- [ ] AWS Batch
- [ ] ...

__Stream Processing:__
- [ ] Kafka
- [ ] Pulsar
- [ ] Kinesis
- [ ] â€¦

---

### Dashboard Tiles:
- 1 graph that shows the distribution of some categorical data
- 1 graph that shows the distribution of the data across a temporal line

---

### Security:
- TODO: define RBAC model

### Extra Mile:
- Tests
- Logs
- CI/CD Pipeline
- Helpful links
    - Unit Tests + CI for Airflow
    - CI/CD for Airflow (with Gitlab & GCP state file)
    - CI/CD for Airflow (with GitHub and S3 state file)
    - CD for Terraform
    - Spark + Airflow


---
---
